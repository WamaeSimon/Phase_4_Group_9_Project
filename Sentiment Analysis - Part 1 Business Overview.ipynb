{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets on Apple and Google Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](NLP_Image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. BUSINESS OVERVIEW  \n",
    "\n",
    "###  1.1 **Business Understanding**\n",
    "\n",
    "#### 1.1.1 **What is  sentiment analysis?**\n",
    "\n",
    "**Sentiment Analysis** also known as **Sentiment Classification** in brief uses natural language processing to identify the emotional tone behind text, such as customer feedback, and categorize it as positive, negative, or neutral. \n",
    "\n",
    "The above can also be described as a text classification tasks, where we look at a phrase, or a list of phrases and use a classifier to tell if the sentiment behind that is:\n",
    "- positive\n",
    "- negative \n",
    "- neutral. \n",
    "\n",
    "In some cases, the third attribute is not taken to keep it a binary classification problem. \n",
    "\n",
    "In this project we will thus carry out a sentiment classification task where we will analyzes tweets, their emotions, and whether they are directed at a brand or product i.e Apple and Google products\n",
    "\n",
    "#### 1.1.2 **How is sentiment analysis important to an organization?**\n",
    "\n",
    "For your organization, sentiment analysis is crucial in the following ways:\n",
    "\n",
    "- Understanding customer opinions for improving experiences, and addressing concerns proactively. \n",
    "- It helps to predict customer behavior for a particular product\n",
    "- It can help to test the adaptability of a product\n",
    "- Automates the task of customer preference reports.\n",
    "\n",
    "The above are but a few benefits, but in general sentiment analysis assit business stake holders to also define various business problems regarding their products\n",
    "#### 1.1.3 **An Overview of Apple Products**\n",
    "Apple is one of the most recognized brands in the world valued at over $2 trillion in 2021. It is known for its innovative consumer electronics, including the iPhone, iPad, MacBook, and other devices. Apple’s next products, which may include a virtual reality headset and self-driving car. The past few product launches have been smaller in scope, like the HomePod and AirPod, and Apple fans are clamouring for the next iPhone.Given their wide range of products some mentioned above , below we have some statistics on their performance in 2023 as at September: \n",
    "\n",
    "- 231 million iPhones, 49 million iPads and 22 million Mac and MacBook units were sold in 2023\n",
    "- Apple’s home and wearables division declined by 6.5% in 2023\n",
    "- It sold 75 million AirPods and 38 million Apple Watches in 2023\n",
    "- Apple Music has 93 million subscribers, Apple TV+ has 47 million\n",
    "\n",
    "To be able to consistently get high revenues, Apple needs to continuously carry out sentiment analysis on the users' strong emotional reactions to the brand , which frequently result in a mix of positive and negative sentiments in their data.Tweets being a source of helpful data , looking at Tweets on Apple products could, among other things, cover customer service experiences, software upgrades, or the introduction of new items. \n",
    "\n",
    "\n",
    "#### 1.1.4 **An Overview of Google Products**\n",
    "\n",
    "Google offers diverse products designed to enhance productivity, connectivity, and innovation.Key offerings include:\n",
    "- Google Search\n",
    "- Gmail\n",
    "- Google Drive\n",
    "- Google Workspace for organizing and collaborating\n",
    "- YouTube\n",
    "- Google Photos\n",
    "- Google Play for entertainment\n",
    "- Google Maps, Waze, and Google Earth for navigation. \n",
    "- Businesses benefit from Google Ads, Google Analytics, and Google Cloud Platform, while developers use tools like Firebase and   BigQuery.\n",
    "\n",
    "Additionally, smart devices like Pixel phones, Nest home products, and Chromecast provide cutting-edge hardware solutions. Overall, Google's products aim to simplify daily life, empower businesses, and connect the world. In 2021 Statistics Highlighting Google's performance showed a revenue of $278.1 billion. Similar to Apple, for Google to continue to thrive, sentiment analysis is thus crucial to check on matters such as customer satisfaction.\n",
    "\n",
    "#### 1.1.5 **Why Analyze Tweets?**\n",
    "- **Social Media Influence**: Platforms like Twitter have become primary channels where customers share their feedback, both positive and negative, about brands and products.\n",
    "- **Volume of Data**: The massive and real-time nature of tweets makes manual analysis impractical, necessitating automated solutions.\n",
    "- **Business Impact**: Sentiment analysis of tweets can provide actionable insights to enhance customer experience, refine marketing strategies, and maintain a competitive edge.\n",
    "\n",
    "\n",
    "#### 1.1.6   Stakeholders \n",
    "\n",
    "Sentiment analysis is important for various participants such as:\n",
    "\n",
    "- **Business Managers**: Understand customer satisfaction and drive decision-making.\n",
    "- **Marketing Teams**: Create sentiment-driven marketing campaigns.\n",
    "- **Customer Service Teams**: Prioritize resolving issues flagged in negative reviews.\n",
    "\n",
    "#### 1.1.7 **Challenges in Sentiment Analysis**\n",
    "- **Unstructured Data**: Tweets are often informal, with abbreviations, slang, and emojis, making preprocessing essential.\n",
    "- **Ambiguity**: Some texts may have mixed sentiments or implicit emotions that are challenging to classify.\n",
    "- **Scalability**: Handling and processing large datasets efficiently is a significant challenge.\n",
    "\n",
    "#### 1.1.8 **Proposed Solutions**\n",
    "##### 1.1.8 Approach Methodology: \n",
    "\n",
    "##### 1.To execute the sentiment analysis . The following is the execution plan:\n",
    "- Begin with simple approaches like bag-of-words or TF-IDF vectorization \n",
    "- Proceed to commplex methods (e.g., word embeddings or transformers)\n",
    "\n",
    "##### 2. Pre-trained Tools: \n",
    "* NLP has many pre-trained models (e.g., spaCy, NLTK, Hugging Face Transformers) and libraries for quick text processing. \n",
    "\n",
    "For example, use:\n",
    "- TF-IDF + Logistic Regression for a baseline.\n",
    "- Pre-trained embeddings (e.g., Word2Vec, GloVe) for better results.\n",
    "- Fine-tuned BERT if there is access to good hardware.\n",
    "\n",
    "#### 1.1.9 Projected Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2 **Problem statement**\n",
    "\n",
    "#### 1.2.1  Business Problem:\n",
    "- In today’s digital world, customer feedback plays a critical role in shaping business decisions. Companies receive large volumes of unstructured textual data in the form of reviews, surveys, and social media posts. Analyzing this data manually is time-consuming and error-prone.\n",
    "\n",
    "The goal of this project is to build a sentiment analysis model that classifies customer feedback as positive, negative, or neutral. \n",
    "\n",
    "This will enable businesses to:\n",
    "- Identify key areas for improvement.\n",
    "- Tailor marketing strategies based on customer sentiment.\n",
    "- Monitor brand reputation over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.3 **Objectives**\n",
    "\n",
    "#### 1. **Primary Objective**:\n",
    "   - Build a machine learning-based sentiment classification model that categorizes tweets as **positive**, **negative**, or **neutral** towards a brand or product.\n",
    "   \n",
    "#### 2. **Secondary Objectives**:\n",
    "   - Identify whether a tweet contains an emotion directed at a specific brand or product.\n",
    "   - Preprocess and clean the tweet text to remove noise (e.g., hashtags, mentions, and URLs).\n",
    "   - Extract key textual features that indicate sentiment and brand-related emotions.\n",
    "   - Provide actionable insights to help businesses improve customer satisfaction and marketing strategies.   \n",
    "   \n",
    "###  1.3.1 **Key Questions to Address**\n",
    "1. How can we preprocess and clean textual data effectively to extract meaningful insights?\n",
    "2. What are the best features to use (e.g., word embeddings, TF-IDF, or sentiment lexicons) for classifying tweet sentiment?\n",
    "3. Which supervised learning models (e.g., Logistic Regression, Random Forest, or BERT) perform best for this task?\n",
    "4. What level of accuracy, precision, and recall can we achieve for sentiment classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.4 **Metrics of Success**\n",
    "\n",
    "To evaluate the success of our sentiment analysis model, we will use metrics such as; accuracy, precision, recall or sensitivity, f1 score and the confusion matrix. To evaluate the performance of the sentiment classification model, we will use the following metrics:\n",
    "#### 1. **Accuracy**:\n",
    "   - Accuracy will check at the percentage of the correctly classified instances of sentiments out of the total sentmental            instances.\n",
    "   - Target: **85% or higher**.\n",
    "\n",
    "#### 2. **Precision**:\n",
    "   - Precision will tell the percentage of actually correct positive sentiment predictions, thus telling us how often the model      is correct when it predicts a positive sentiment. The percentage of actual positive sentiments, that are correctly              identified by the model will be shown by recall. This metrics is important to strike a tradeoff between true positives and      false negatives\n",
    "   - Target: **80% or higher** for each class (positive, negative, neutral).\n",
    "\n",
    "#### 3. **Recall**:\n",
    "   - Measure the model’s ability to correctly identify all relevant examples of a specific sentiment.\n",
    "   - Target: **75% or higher** for each class.\n",
    "\n",
    "#### 4. **F1-Score**:\n",
    "   - Provide a balanced metric that considers both precision and recall.\n",
    "   - Target: **80% or higher** overall.\n",
    "\n",
    "#### 5. **Business Impact**:\n",
    "   - Improved customer satisfaction through the identification of key negative sentiments.\n",
    "   - Better marketing strategies based on trends in positive feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DATA UNDERSTANDING\n",
    "* Now we load the data, and proceed with understanding the shape, the basic statistics and the types of variable.\n",
    "* We write function that we can load the data and get back the shape, info and description with df.shape, df.describe(), df.info() and df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Import Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Project_Functions as Pf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 General  Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Display the first few rows of the dataset\n",
    "df = Pf.Load_dataset('judge-1377884607_tweet_product_company.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9093, 3)\n",
      "===============The dataset columns=================\n",
      "Index(['tweet_text', 'emotion_in_tweet_is_directed_at',\n",
      "       'is_there_an_emotion_directed_at_a_brand_or_product'],\n",
      "      dtype='object')\n",
      "===============The data_types=================\n",
      "tweet_text                                            object\n",
      "emotion_in_tweet_is_directed_at                       object\n",
      "is_there_an_emotion_directed_at_a_brand_or_product    object\n",
      "dtype: object\n",
      "===============The dataset information=================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n",
      "None\n",
      "===============Check for Missing values=================\n",
      "tweet_text                                               1\n",
      "emotion_in_tweet_is_directed_at                       5802\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n",
      "===============Check for Duplicated Rows=================\n",
      "22\n",
      "===============The dataset Description=================\n",
      "                                               tweet_text  \\\n",
      "count                                                9092   \n",
      "unique                                               9065   \n",
      "top     RT @mention Marissa Mayer: Google Will Connect...   \n",
      "freq                                                    5   \n",
      "\n",
      "       emotion_in_tweet_is_directed_at  \\\n",
      "count                             3291   \n",
      "unique                               9   \n",
      "top                               iPad   \n",
      "freq                               946   \n",
      "\n",
      "       is_there_an_emotion_directed_at_a_brand_or_product  \n",
      "count                                                9093  \n",
      "unique                                                  4  \n",
      "top                    No emotion toward brand or product  \n",
      "freq                                                 5389  \n"
     ]
    }
   ],
   "source": [
    "# Show the data information\n",
    "Pf.check_Info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset comprise of 9093 rows and 3 columns; th tweet_text',emotion_in_tweet_is_directed_at, and is_there_an_emotion_directed_at_a_brand_or_product. \n",
    "* The tweet_text column contain the tweet or the text written on the twitter platform. The 'emotion_in_tweet_is_directed_at' column shows the company, google or apple, that the tweet was directed at. The last column shows whether the tweet written had a positive, negative or neutral impact. \n",
    "* All the columns are of the object data type.\n",
    "* There are 5802 missing entries in the 'emotion_in_tweet_is_directed_at' column and one missing entry in the tweet_text column.\n",
    "* There are 22 duplicated entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DATA PREPARATION\n",
    "The data understanding section above checked for non null values, duplicates to gain surface level insights. This section delves into data preparation by performing various transformations suitable format for modelling.\n",
    "But first we need to do a bit of data cleaning.\n",
    "####  3.1  Data Cleaning\n",
    "1. Deal with the missing values in the tweet_text and emotion_in_tweet_is_directed_at columns\n",
    "2. Deal with Duplicates\n",
    "3. Dealing with the text case\n",
    "4. Further cleaning and transformation; Removing specific words and numbers in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.1  Duplicates\n",
    "* Drop the duplicated rows.\n",
    "Rationale; The total number of duplictes, i.e 22. we remove them to maintain the integrity of our data set and only ensure only unique observations are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.2  Missing Values\n",
    "* Drop the row with missing values in the tweet_text column. Implement the use of the dropna() pandas method.\n",
    "* The 'emotion_in_tweet_is_directed_at' column, require strict check in regard to its contribution to the final model. Check for the percentage of the missing values; above 50%. With the trade off between droping this column and retaining it, try a method to get an absolute and rational values for the missing entries. \n",
    "* Loop through the tweet_text column texts and check for a probable entry. Fill in this entries to a new column. To do this, first, clean the tweet_text column and create a column for the cleaned text, then extract the possible entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null value in tweet_text column.\n",
    "df = df.dropna(subset = ['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_text                                               0\n",
      "emotion_in_tweet_is_directed_at                       5788\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Pf.check_for_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.638148\n",
       "False    0.361852\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: float64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].isna().value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.2.1  Dealing with the text column\n",
    "1. Basic cleaning: removing capitalization, special characters such as ?,;., converting to lower case\n",
    "2. Tokenizing our texts column\n",
    "3. create a new column with joined words\n",
    "4. removing the stopwords\n",
    "\n",
    "* First extract the words in the tweet_text column that starts with '@' and those starting with '#'. words starting with @ refers to the person who tweeted while those those starting with # refers to those who were tagged. worth notting that these words in our texts will be adding noise to our data_set.\n",
    "* Extract the users and the tagged into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Usernames</th>\n",
       "      <th>Tagged_Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[@wesley83]</td>\n",
       "      <td>[#RISE_Austin, #SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[@jessedee, @fludapp]</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[@swonderlin]</td>\n",
       "      <td>[#iPad, #SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[@sxsw]</td>\n",
       "      <td>[#sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[@sxtxstate]</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product              Usernames  \\\n",
       "0                                   Negative emotion            [@wesley83]   \n",
       "1                                   Positive emotion  [@jessedee, @fludapp]   \n",
       "2                                   Positive emotion          [@swonderlin]   \n",
       "3                                   Negative emotion                [@sxsw]   \n",
       "4                                   Positive emotion           [@sxtxstate]   \n",
       "\n",
       "            Tagged_Names  \n",
       "0  [#RISE_Austin, #SXSW]  \n",
       "1                [#SXSW]  \n",
       "2         [#iPad, #SXSW]  \n",
       "3                [#sxsw]  \n",
       "4                [#SXSW]  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "# Regular expression to extract Twitter usernames\n",
    "pattern = r\"@\\w+\"\n",
    "pattern_2 = r'#\\w+'\n",
    "\n",
    "# Extract usernames from the 'Tweets' column\n",
    "df['Usernames'] = df['tweet_text'].apply(lambda x: re.findall(pattern, x))\n",
    "df['Tagged_Names'] = df['tweet_text'].apply(lambda x: re.findall(pattern_2, x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.2.2  Converting the tweet_text to lower case\n",
    "* Write a function to access the tweets in the column, tweet_text, and lower case.\n",
    "* Remove the usernames and tagged names in the texts and create the column 'clean_tweet_text' for the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the whole dataset (df[tweet_text]) to lowercase\n",
    "df[\"tweet_text\"] = df[\"tweet_text\"].str.lower()\n",
    "# Display full text: uncomment the code below to display the whole texts\n",
    "#df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that removes words starting with @ and #\n",
    "def remove_words_with_at(text):\n",
    "    # Use a regular expression to remove words containing \"@\" and words starting with \"#\"\n",
    "    cleaned_text = re.sub(r'\\S*@\\S*|#\\w+','', text)\n",
    "  \n",
    "    return cleaned_text\n",
    "# Create new column with tokenized data\n",
    "df[\"clean_tweet_text\"] = df[\"tweet_text\"].apply(remove_words_with_at)\n",
    "# Display full text: uncomment the code below to display the whole texts\n",
    "#df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now loop through the tweet_text column and check for a probable entry. Fill in this entries to a new column, category_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Google                                   2156\n",
       "                                         1781\n",
       "iPad iPad                                1713\n",
       "Apple                                    1191\n",
       "iPhone                                    832\n",
       "iPad Apple iPad                           568\n",
       "Android                                   240\n",
       "iPhone App iPhone                         208\n",
       "iPhone Android                            101\n",
       "iPad iPad iPhone                           98\n",
       "Android App Android                        30\n",
       "Apple Google                               23\n",
       "iPad iPad Android                          23\n",
       "Apple iPhone                               22\n",
       "iPhone App iPhone Android                  17\n",
       "Google Android                             15\n",
       "iPad iPad Google                           10\n",
       "iPad iPad iPhone Android                    8\n",
       "Apple Android                               7\n",
       "iPhone Android App Android                  6\n",
       "iPad iPad iPhone App iPhone                 5\n",
       "iPhone App iPhone Android App Android       4\n",
       "iPad Apple iPad iPhone                      4\n",
       "Google iPhone                               3\n",
       "iPad iPad Google iPhone                     2\n",
       "Google iPhone Android                       2\n",
       "Apple iPhone App iPhone                     1\n",
       "Name: Tweet_Directed_at, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_category_words(tweet, categories):\n",
    "    # Tokenize and check for category words\n",
    "    extracted_words = []\n",
    "    for category in categories:\n",
    "        if category.lower() in tweet.lower():\n",
    "            extracted_words.append(category)\n",
    "    return \" \".join(extracted_words)\n",
    "df['Tweet_Directed_at'] = df['clean_tweet_text'].apply(lambda x: extract_category_words(x, categories))\n",
    "# Check for the value counts in the new category column\n",
    "df['Tweet_Directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Tweet_Directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>i have a 3g iphone. after 3 hrs tweeting at ,...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>know about  ? awesome ipad/iphone app that yo...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>iPad iPad iPhone App iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...   \n",
       "\n",
       "                                    clean_tweet_text  \\\n",
       "0   i have a 3g iphone. after 3 hrs tweeting at ,...   \n",
       "1   know about  ? awesome ipad/iphone app that yo...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at            Tweet_Directed_at  \\\n",
       "0                          iPhone                       iPhone   \n",
       "1              iPad or iPhone App  iPad iPad iPhone App iPhone   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging the dataframe.\n",
    "df= df[['tweet_text', 'clean_tweet_text','emotion_in_tweet_is_directed_at','Tweet_Directed_at',\n",
    "       'is_there_an_emotion_directed_at_a_brand_or_product']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From above display of the value counts, the category_words columns have 1781 null entries.\n",
    "* Loop through the 'category_words' to determine which entries were null. For the indices of the null entries, check if they are present in the 'emotion_in_tweet_is_directed_at' column. If present, fill in the null entries in the category_words.\n",
    "* Access the value counts of the category_words column to verify the decrease in the null entries. Notice a decrease in the number of null entries.\n",
    "* Proceed to drop the rows with null entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for rows where emotion_in_tweet_is_directed_at has data, but clean_tweet_text is blank\n",
    "condition_a_data_b_blank = (df['emotion_in_tweet_is_directed_at'].notna() & (df['emotion_in_tweet_is_directed_at'] != \"\") & \n",
    "                            (df['Tweet_Directed_at'].isna() | (df['Tweet_Directed_at'] == \"\")))\n",
    "\n",
    "# Update the 'category_words' column with the values from 'emotion_in_tweet_is_directed_at'\n",
    "df.loc[condition_a_data_b_blank, 'Tweet_Directed_at'] = df.loc[condition_a_data_b_blank, 'emotion_in_tweet_is_directed_at']\n",
    "# Uncomment the cell below to show the value counts\n",
    "# df['Tweet_Directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a mapping for the either google products, apple products, unknown and IRR. Map this dictionary to create a column to show which company the tweet was directed at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple Products     0.547550\n",
       "Google Products    0.282949\n",
       "Unknown            0.159767\n",
       "IRR                0.009734\n",
       "Name: Company_Product, dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define mapping for fewer categories\n",
    "category_mapping = {\n",
    "    'Google': 'Google Products',\n",
    "    '': 'Unknown',\n",
    "    'iPad iPad': 'Apple Products',\n",
    "    'Apple': 'Apple Products',\n",
    "    'iPhone': 'Apple Products',\n",
    "    'iPad Apple iPad': 'Apple Products',\n",
    "    'Android': 'Google Products',\n",
    "    'iPhone App iPhone': 'Apple Products',\n",
    "    'iPad iPad iPhone': 'Apple Products',\n",
    "    'Android App Android': 'Google Products',\n",
    "    'Apple Google': 'IRR',\n",
    "    'iPad iPad Android': 'IRR',\n",
    "    'Apple iPhone': 'Apple Products',\n",
    "    'iPhone App iPhone Android': 'IRR',\n",
    "    'Google Android': 'Google Products',\n",
    "    'iPad iPad Google': 'IRR',\n",
    "    'iPad iPad iPhone Android': 'IRR',\n",
    "    'iPad iPad iPhone App iPhone': 'Apple Products',\n",
    "    'iPhone App iPhone Android App Android': 'IRR',\n",
    "    'iPad Apple iPad iPhone': 'Apple Products',\n",
    "    'iPad iPad Google iPhone': 'IRR',\n",
    "    'Apple iPhone App iPhone': 'Apple Products',\n",
    "    'iPad': 'Apple Products',\n",
    "    'iPad or iPhone App': 'Apple Products',\n",
    "    'Android App': 'Google Products',\n",
    "    'Other Google product or service': 'Google Products',\n",
    "    'Other Apple product or service ': 'Apple Products'  \n",
    "}\n",
    "\n",
    "# Apply mapping to the dataframe\n",
    "df['Company_Product'] = df['Tweet_Directed_at'].map(category_mapping)\n",
    "df.head()\n",
    "# Display the result\n",
    "df['Company_Product'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any null values in the Company_product column\n",
    "df['Company_Product'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The presence of 132 null values in the company_product column is reflective of the entries that could not be mapped from the 'tweet text' and also could not be mapped from 'emotion_in_tweet_is_directed_at' and 'Tweet_Directed_at' columns. Proceed to drop the null rows in this column.\n",
    "* Then proceed to drop the 'emotion_in_tweet_is_directed_at' column, because the 'Company_product' is a better representative of this column. Now we have successfully dealt with the missing values. Proceed to dealing with the clean_tweet_text column semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['Company_Product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_text                                               0\n",
      "clean_tweet_text                                         0\n",
      "emotion_in_tweet_is_directed_at                       4216\n",
      "Tweet_Directed_at                                        0\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "Company_Product                                          0\n",
      "text_tokenized                                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Droping rows with null entries\n",
    "df = df[(df['Company_Product'] != 'Unknown') & (df['Company_Product'] != 'IRR')]\n",
    "df = df.reset_index(drop=True)\n",
    "# Confirm the null entries\n",
    "Pf.check_for_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Company_Product'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.2 Data Cleaning & EDA with NLTK\n",
    "1. Remove URLs\n",
    "2. remove non-alphanumeric characters\n",
    "3. Remove numbers/ digits\n",
    "\n",
    "#####  3.2.1\n",
    "* In this section we access the clean_tweet_text column check for the appropriate checks in the text. For instance, removal of special characters, Urls and numbers/digits.\n",
    "* Create a function that removes all the instances above.\n",
    "* Access specific text, perform the transformations and apply to the whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'before it even begins,  wins  {link}  '"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = df['clean_tweet_text'][377]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the apple   has taken  and  by storm link   excited to a be a part '"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean text (remove unwanted characters and convert to lowercase)\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # confirm mentions (@user)\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    return text\n",
    "\n",
    "#df['cleaned_tweet'] = df['tweet_text'].apply(clean_text)\n",
    "cleaned_sentence = clean_text(sentence)\n",
    "cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gotta',\n",
       " 'love',\n",
       " 'this',\n",
       " 'google',\n",
       " 'calendar',\n",
       " 'featuring',\n",
       " 'top',\n",
       " 'parties',\n",
       " 'show',\n",
       " 'cases',\n",
       " 'to',\n",
       " 'check',\n",
       " 'out',\n",
       " 'rt',\n",
       " 'via',\n",
       " 'gt',\n",
       " 'http',\n",
       " 'bit',\n",
       " 'ly',\n",
       " 'axzwxb']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the regexptokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice that the regexpTokenizer removes all the special characters, including urls. It splits the specific words and puts them into a list. However the it does not remove the stopwords/ filler words and numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Tweet_Directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Company_Product</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>i have a 3g iphone. after 3 hrs tweeting at ,...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "      <td>[have, 3g, iphone, after, hrs, tweeting, at, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>know about  ? awesome ipad/iphone app that yo...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>iPad iPad iPhone App iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "      <td>[know, about, awesome, ipad, iphone, app, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>can not wait for  2 also. they should sale th...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "      <td>[can, not, wait, for, also, they, should, sale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...   \n",
       "\n",
       "                                    clean_tweet_text  \\\n",
       "0   i have a 3g iphone. after 3 hrs tweeting at ,...   \n",
       "1   know about  ? awesome ipad/iphone app that yo...   \n",
       "2   can not wait for  2 also. they should sale th...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at            Tweet_Directed_at  \\\n",
       "0                          iPhone                       iPhone   \n",
       "1              iPad or iPhone App  iPad iPad iPhone App iPhone   \n",
       "2                            iPad                         iPad   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product Company_Product  \\\n",
       "0                                   Negative emotion  Apple Products   \n",
       "1                                   Positive emotion  Apple Products   \n",
       "2                                   Positive emotion  Apple Products   \n",
       "\n",
       "                                      text_tokenized  \n",
       "0  [have, 3g, iphone, after, hrs, tweeting, at, i...  \n",
       "1  [know, about, awesome, ipad, iphone, app, that...  \n",
       "2  [can, not, wait, for, also, they, should, sale...  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column with tokenized data\n",
    "df[\"text_tokenized\"] = df[\"clean_tweet_text\"].apply(tokenizer.tokenize)\n",
    "# Display full text\n",
    "#df.style.set_properties(**{'text-align': 'left'})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numerical values using regex\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+','', text)\n",
    "# Check if the function works with our sentence\n",
    "clean_sentence = remove_numbers(sentence)\n",
    "clean_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
