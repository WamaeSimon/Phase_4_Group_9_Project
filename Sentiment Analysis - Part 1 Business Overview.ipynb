{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets on Apple and Google Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](NLP_Image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. BUSINESS OVERVIEW  \n",
    "\n",
    "###  1.1 **Business Understanding**\n",
    "\n",
    "#### 1.1.1 **What is  sentiment analysis?**\n",
    "\n",
    "**Sentiment Analysis** also known as **Sentiment Classification** in brief uses natural language processing to identify the emotional tone behind text, such as customer feedback, and categorize it as positive, negative, or neutral. \n",
    "\n",
    "The above can also be described as a text classification tasks, where we look at a phrase, or a list of phrases and use a classifier to tell if the sentiment behind that is:\n",
    "- positive\n",
    "- negative \n",
    "- neutral. \n",
    "\n",
    "In some cases, the third attribute is not taken to keep it a binary classification problem. \n",
    "\n",
    "In this project we will thus carry out a sentiment classification task where we will analyzes tweets, their emotions, and whether they are directed at a brand or product i.e Apple and Google products\n",
    "\n",
    "#### 1.1.2 **How is sentiment analysis important to an organization?**\n",
    "\n",
    "For your organization, sentiment analysis is crucial in the following ways:\n",
    "\n",
    "- Understanding customer opinions for improving experiences, and addressing concerns proactively. \n",
    "- It helps to predict customer behavior for a particular product\n",
    "- It can help to test the adaptability of a product\n",
    "- Automates the task of customer preference reports.\n",
    "\n",
    "The above are but a few benefits, but in general sentiment analysis assit business stake holders to also define various business problems regarding their products\n",
    "#### 1.1.3 **An Overview of Apple Products**\n",
    "Apple is one of the most recognized brands in the world valued at over $2 trillion in 2021. It is known for its innovative consumer electronics, including the iPhone, iPad, MacBook, and other devices. Apple’s next products, which may include a virtual reality headset and self-driving car. The past few product launches have been smaller in scope, like the HomePod and AirPod, and Apple fans are clamouring for the next iPhone.Given their wide range of products some mentioned above , below we have some statistics on their performance in 2023 as at September: \n",
    "\n",
    "- 231 million iPhones, 49 million iPads and 22 million Mac and MacBook units were sold in 2023\n",
    "- Apple’s home and wearables division declined by 6.5% in 2023\n",
    "- It sold 75 million AirPods and 38 million Apple Watches in 2023\n",
    "- Apple Music has 93 million subscribers, Apple TV+ has 47 million\n",
    "\n",
    "To be able to consistently get high revenues, Apple needs to continuously carry out sentiment analysis on the users' strong emotional reactions to the brand , which frequently result in a mix of positive and negative sentiments in their data.Tweets being a source of helpful data , looking at Tweets on Apple products could, among other things, cover customer service experiences, software upgrades, or the introduction of new items. \n",
    "\n",
    "\n",
    "#### 1.1.4 **An Overview of Google Products**\n",
    "\n",
    "Google offers diverse products designed to enhance productivity, connectivity, and innovation.Key offerings include:\n",
    "- Google Search\n",
    "- Gmail\n",
    "- Google Drive\n",
    "- Google Workspace for organizing and collaborating\n",
    "- YouTube\n",
    "- Google Photos\n",
    "- Google Play for entertainment\n",
    "- Google Maps, Waze, and Google Earth for navigation. \n",
    "- Businesses benefit from Google Ads, Google Analytics, and Google Cloud Platform, while developers use tools like Firebase and   BigQuery.\n",
    "\n",
    "Additionally, smart devices like Pixel phones, Nest home products, and Chromecast provide cutting-edge hardware solutions. Overall, Google's products aim to simplify daily life, empower businesses, and connect the world. In 2021 Statistics Highlighting Google's performance showed a revenue of $278.1 billion. Similar to Apple, for Google to continue to thrive, sentiment analysis is thus crucial to check on matters such as customer satisfaction.\n",
    "\n",
    "#### 1.1.5 **Why Analyze Tweets?**\n",
    "- **Social Media Influence**: Platforms like Twitter have become primary channels where customers share their feedback, both positive and negative, about brands and products.\n",
    "- **Volume of Data**: The massive and real-time nature of tweets makes manual analysis impractical, necessitating automated solutions.\n",
    "- **Business Impact**: Sentiment analysis of tweets can provide actionable insights to enhance customer experience, refine marketing strategies, and maintain a competitive edge.\n",
    "\n",
    "\n",
    "#### 1.1.6   Stakeholders \n",
    "\n",
    "Sentiment analysis is important for various participants such as:\n",
    "\n",
    "- **Business Managers**: Understand customer satisfaction and drive decision-making.\n",
    "- **Marketing Teams**: Create sentiment-driven marketing campaigns.\n",
    "- **Customer Service Teams**: Prioritize resolving issues flagged in negative reviews.\n",
    "\n",
    "#### 1.1.7 **Challenges in Sentiment Analysis**\n",
    "- **Unstructured Data**: Tweets are often informal, with abbreviations, slang, and emojis, making preprocessing essential.\n",
    "- **Ambiguity**: Some texts may have mixed sentiments or implicit emotions that are challenging to classify.\n",
    "- **Scalability**: Handling and processing large datasets efficiently is a significant challenge.\n",
    "\n",
    "#### 1.1.8 **Proposed Solutions**\n",
    "##### 1.1.8 Approach Methodology: \n",
    "\n",
    "##### 1.To execute the sentiment analysis . The following is the execution plan:\n",
    "- Begin with simple approaches like bag-of-words or TF-IDF vectorization \n",
    "- Proceed to commplex methods (e.g., word embeddings or transformers)\n",
    "\n",
    "##### 2. Pre-trained Tools: \n",
    "* NLP has many pre-trained models (e.g., spaCy, NLTK, Hugging Face Transformers) and libraries for quick text processing. \n",
    "\n",
    "For example, use:\n",
    "- TF-IDF + Logistic Regression for a baseline.\n",
    "- Pre-trained embeddings (e.g., Word2Vec, GloVe) for better results.\n",
    "- Fine-tuned BERT if there is access to good hardware.\n",
    "\n",
    "#### 1.1.9 Projected Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2 **Problem statement**\n",
    "\n",
    "#### 1.2.1  Business Problem:\n",
    "- In today’s digital world, customer feedback plays a critical role in shaping business decisions. Companies receive large volumes of unstructured textual data in the form of reviews, surveys, and social media posts. Analyzing this data manually is time-consuming and error-prone.\n",
    "\n",
    "The goal of this project is to build a sentiment analysis model that classifies customer feedback as positive, negative, or neutral. \n",
    "\n",
    "This will enable businesses to:\n",
    "- Identify key areas for improvement.\n",
    "- Tailor marketing strategies based on customer sentiment.\n",
    "- Monitor brand reputation over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.3 **Objectives**\n",
    "\n",
    "#### 1. **Primary Objective**:\n",
    "   - Build a machine learning-based sentiment classification model that categorizes tweets as **positive**, **negative**, or **neutral** towards a brand or product.\n",
    "   \n",
    "#### 2. **Secondary Objectives**:\n",
    "   - Identify whether a tweet contains an emotion directed at a specific brand or product.\n",
    "   - Preprocess and clean the tweet text to remove noise (e.g., hashtags, mentions, and URLs).\n",
    "   - Extract key textual features that indicate sentiment and brand-related emotions.\n",
    "   - Provide actionable insights to help businesses improve customer satisfaction and marketing strategies.   \n",
    "   \n",
    "###  1.3.1 **Key Questions to Address**\n",
    "1. How can we preprocess and clean textual data effectively to extract meaningful insights?\n",
    "2. What are the best features to use (e.g., word embeddings, TF-IDF, or sentiment lexicons) for classifying tweet sentiment?\n",
    "3. Which supervised learning models (e.g., Logistic Regression, Random Forest, or BERT) perform best for this task?\n",
    "4. What level of accuracy, precision, and recall can we achieve for sentiment classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.4 **Metrics of Success**\n",
    "\n",
    "To evaluate the success of our sentiment analysis model, we will use metrics such as; accuracy, precision, recall or sensitivity, f1 score and the confusion matrix. To evaluate the performance of the sentiment classification model, we will use the following metrics:\n",
    "#### 1. **Accuracy**:\n",
    "   - Accuracy will check at the percentage of the correctly classified instances of sentiments out of the total sentmental            instances.\n",
    "   - Target: **85% or higher**.\n",
    "\n",
    "#### 2. **Precision**:\n",
    "   - Precision will tell the percentage of actually correct positive sentiment predictions, thus telling us how often the model      is correct when it predicts a positive sentiment. The percentage of actual positive sentiments, that are correctly              identified by the model will be shown by recall. This metrics is important to strike a tradeoff between true positives and      false negatives\n",
    "   - Target: **80% or higher** for each class (positive, negative, neutral).\n",
    "\n",
    "#### 3. **Recall**:\n",
    "   - Measure the model’s ability to correctly identify all relevant examples of a specific sentiment.\n",
    "   - Target: **75% or higher** for each class.\n",
    "\n",
    "#### 4. **F1-Score**:\n",
    "   - Provide a balanced metric that considers both precision and recall.\n",
    "   - Target: **80% or higher** overall.\n",
    "\n",
    "#### 5. **Business Impact**:\n",
    "   - Improved customer satisfaction through the identification of key negative sentiments.\n",
    "   - Better marketing strategies based on trends in positive feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DATA UNDERSTANDING\n",
    "* Now we load the data, and proceed with understanding the shape, the basic statistics and the types of variable.\n",
    "* We write function that we can load the data and get back the shape, info and description with df.shape, df.describe(), df.info() and df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Import Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tracy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tracy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tracy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tracy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Project_Functions as Pf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import words\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 General  Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1578,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9088                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9089                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9090  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9091       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9092                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 1578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Display the first few rows of the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\tracy\\Documents\\Flatiron\\Phase_4_project\\Phase_4_Group_9_Project\\judge-1377884607_tweet_product_company.csv\", encoding='ISO-8859-1')\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9093, 3)\n",
      "===============The dataset columns=================\n",
      "Index(['tweet_text', 'emotion_in_tweet_is_directed_at',\n",
      "       'is_there_an_emotion_directed_at_a_brand_or_product'],\n",
      "      dtype='object')\n",
      "===============The data_types=================\n",
      "tweet_text                                            object\n",
      "emotion_in_tweet_is_directed_at                       object\n",
      "is_there_an_emotion_directed_at_a_brand_or_product    object\n",
      "dtype: object\n",
      "===============The dataset information=================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n",
      "None\n",
      "===============Check for Missing values=================\n",
      "tweet_text                                               1\n",
      "emotion_in_tweet_is_directed_at                       5802\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n",
      "===============Check for Duplicated Rows=================\n",
      "22\n",
      "===============The dataset Description=================\n",
      "                                                                                                            tweet_text  \\\n",
      "count                                                                                                             9092   \n",
      "unique                                                                                                            9065   \n",
      "top     RT @mention Marissa Mayer: Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxsw   \n",
      "freq                                                                                                                 5   \n",
      "\n",
      "       emotion_in_tweet_is_directed_at  \\\n",
      "count                             3291   \n",
      "unique                               9   \n",
      "top                               iPad   \n",
      "freq                               946   \n",
      "\n",
      "       is_there_an_emotion_directed_at_a_brand_or_product  \n",
      "count                                                9093  \n",
      "unique                                                  4  \n",
      "top                    No emotion toward brand or product  \n",
      "freq                                                 5389  \n"
     ]
    }
   ],
   "source": [
    "# Show the data information\n",
    "Pf.check_Info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['iPhone', 'iPad or iPhone App', 'iPad', 'Google', nan, 'Android',\n",
       "       'Apple', 'Android App', 'Other Google product or service',\n",
       "       'Other Apple product or service'], dtype=object)"
      ]
     },
     "execution_count": 1580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unique categories in emotion_in_tweet_is_directed_at column\n",
    "df['emotion_in_tweet_is_directed_at'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'Positive emotion',\n",
       "       'No emotion toward brand or product', \"I can't tell\"], dtype=object)"
      ]
     },
     "execution_count": 1581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unique categories in Emotion-directed column\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset comprise of 9093 rows and 3 columns; the **tweet_text**,**emotion_in_tweet_is_directed_at** and **is_there_an_emotion_directed_at_a_brand_or_product**. \n",
    "* The tweet_text column contain the tweet or the text written on the twitter platform. The emotiom_in_tweet_is_directed_at column shows items produced as products or evene services by Apple and Google, that the tweets were directed at. The last column shows whether the tweet written had a positive, negative or neutral impact. \n",
    "* All the columns are of the object data type.\n",
    "* There are 5802 missing entries in the 'emotion_in_tweet_is_directed_at' column and one missing entry in the tweet_text column.\n",
    "* There are 22 duplicated entries.\n",
    "* Additionally unique categories were identified in the emotion_in_tweet_is_directed_at column and is_there_an_emotion_directed_at_a_brand_or_product column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DATA PREPARATION\n",
    "The data understanding section above checked for non null values, duplicates to gain surface level insights. This section delves into data preparation by performing various transformations suitable format for modelling.\n",
    "But first we need to do a bit of data cleaning.\n",
    "####  3.1  Data Cleaning\n",
    "1. Deal with the missing values in the tweet_text and emotion_in_tweet_is_directed_at columns\n",
    "2. Deal with Duplicates\n",
    "3. Dealing with the text case\n",
    "4. Further cleaning and transformation; Removing specific words and numbers in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.1  Duplicates\n",
    "* Drop the duplicated rows.\n",
    "Rationale; The total number of duplictes, i.e 22. we remove them to maintain the integrity of our data set and only ensure only unique observations are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.2  Missing Values\n",
    "* Drop the row with missing values in the tweet_text column. Implement the use of the dropna() pandas method.\n",
    "* The 'emotion_in_tweet_is_directed_at' column, require strict check in regard to its contribution to the final model. Check for the percentage of the missing values; above 50%. With the trade off between droping this column and retaining it, try a method to get an absolute and rational values for the missing entries. \n",
    "* Loop through the tweet_text column texts and check for a probable entry. Fill in this entries to a new column. To do this, first, clean the tweet_text column and create a column for the cleaned text, then extract the possible entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_text emotion_in_tweet_is_directed_at  \\\n",
       "6        NaN                             NaN   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "6                 No emotion toward brand or product  "
      ]
     },
     "execution_count": 1583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the missing values in the tweet_text column\n",
    "df[df['tweet_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing value in tweet_text column. Only one was identified above\n",
    "df = df.dropna(subset = ['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_text                                               0\n",
      "emotion_in_tweet_is_directed_at                       5788\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if missing value is removed in tweet , also check remaining missing values in other columns\n",
    "Pf.check_for_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion_in_tweet_is_directed_at\n",
       "True     63.81%\n",
       "False    36.19%\n",
       "Name: proportion, dtype: object"
      ]
     },
     "execution_count": 1586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the percentage distribution of missing values\n",
    "missing_percentage = df['emotion_in_tweet_is_directed_at'].isna().value_counts(normalize = True)* 100\n",
    "# Format the percentages to include the '%' symbol\n",
    "missing_percentage = missing_percentage.apply(lambda x: f\"{x:.2f}%\")\n",
    "missing_percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.2.1  Dealing with the text column\n",
    "1. Basic cleaning: removing capitalization, special characters such as ?,;., converting to lower case\n",
    "2. Tokenizing our texts column\n",
    "3. create a new column with joined words\n",
    "4. removing the stopwords\n",
    "\n",
    "* First extract the words in the tweet_text column that starts with '@' and those starting with '#'. words starting with @ refers to the person who tweeted while those those starting with # refers to those who were tagged. worth notting that these words in our texts will be adding noise to our data_set.\n",
    "* Extract the users and the tagged into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Usernames</th>\n",
       "      <th>Tagged_Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[@wesley83]</td>\n",
       "      <td>[#RISE_Austin, #SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[@jessedee, @fludapp]</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[@swonderlin]</td>\n",
       "      <td>[#iPad, #SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[@sxsw]</td>\n",
       "      <td>[#sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[@sxtxstate]</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                              @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                           @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4          @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product              Usernames  \\\n",
       "0                                   Negative emotion            [@wesley83]   \n",
       "1                                   Positive emotion  [@jessedee, @fludapp]   \n",
       "2                                   Positive emotion          [@swonderlin]   \n",
       "3                                   Negative emotion                [@sxsw]   \n",
       "4                                   Positive emotion           [@sxtxstate]   \n",
       "\n",
       "            Tagged_Names  \n",
       "0  [#RISE_Austin, #SXSW]  \n",
       "1                [#SXSW]  \n",
       "2         [#iPad, #SXSW]  \n",
       "3                [#sxsw]  \n",
       "4                [#SXSW]  "
      ]
     },
     "execution_count": 1587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "# Regular expression to extract Twitter usernames\n",
    "pattern = r\"@\\w+\"\n",
    "pattern_2 = r'#\\w+'\n",
    "\n",
    "# Extract usernames from the 'Tweets' column\n",
    "df['Usernames'] = df['tweet_text'].apply(lambda x: re.findall(pattern, x))\n",
    "df['Tagged_Names'] = df['tweet_text'].apply(lambda x: re.findall(pattern_2, x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  3.1.2.2  Converting the tweet_text to lower case\n",
    "* Write a function to access the tweets in the column, tweet_text, and lower case.\n",
    "* Remove the usernames and tagged names in the texts and create the column 'clean_tweet_text' for the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the whole dataset (df[tweet_text]) to lowercase\n",
    "df[\"tweet_text\"] = df[\"tweet_text\"].str.lower()\n",
    "# Display full text: uncomment the code below to display the whole texts\n",
    "#df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that removes words starting with @ and #\n",
    "def remove_words_with_at(text):\n",
    "    # Use a regular expression to remove words containing \"@\" and words starting with \"#\"\n",
    "    cleaned_text = re.sub(r'\\S*@\\S*|#\\w+','', text)\n",
    "  \n",
    "    return cleaned_text\n",
    "# Create new column with tokenized data\n",
    "df[\"clean_tweet_text\"] = df[\"tweet_text\"].apply(remove_words_with_at)\n",
    "# Display full text: uncomment the code below to display the whole texts\n",
    "#df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now loop through the tweet_text column and check for a probable entry. Fill in this entries to a new column, category_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['iPhone', 'iPad or iPhone App', 'iPad', 'Google','Android',\n",
    "       'Apple', 'Android App', 'Other Google product or service',\n",
    "       'Other Apple product or service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1591,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet_Directed_at\n",
       "Google                        2156\n",
       "                              1781\n",
       "iPad                          1713\n",
       "Apple                         1191\n",
       "iPhone                        1040\n",
       "iPad Apple                     568\n",
       "Android                        240\n",
       "iPhone Android                 118\n",
       "iPhone iPad                    103\n",
       "Android Android App             30\n",
       "iPad Android                    23\n",
       "iPhone Apple                    23\n",
       "Google Apple                    23\n",
       "Google Android                  15\n",
       "iPad Google                     10\n",
       "iPhone Android Android App      10\n",
       "iPhone iPad Android              8\n",
       "Android Apple                    7\n",
       "iPhone iPad Apple                4\n",
       "iPhone Google                    3\n",
       "iPhone iPad Google               2\n",
       "iPhone Google Android            2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_category_words(tweet, categories):\n",
    "    # Tokenize and check for category words\n",
    "    extracted_words = []\n",
    "    for category in categories:\n",
    "        if category.lower() in tweet.lower():\n",
    "            extracted_words.append(category)\n",
    "    return \" \".join(extracted_words)\n",
    "df['Tweet_Directed_at'] = df['clean_tweet_text'].apply(lambda x: extract_category_words(x, categories))\n",
    "# Check for the value counts in the new category column\n",
    "df['Tweet_Directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>Tweet_Directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.</td>\n",
       "      <td>i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw</td>\n",
       "      <td>know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>iPhone iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw   \n",
       "\n",
       "                                                                                                        clean_tweet_text  \\\n",
       "0                    i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .   \n",
       "1   know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at    \n",
       "\n",
       "  emotion_in_tweet_is_directed_at Tweet_Directed_at  \\\n",
       "0                          iPhone            iPhone   \n",
       "1              iPad or iPhone App       iPhone iPad   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  "
      ]
     },
     "execution_count": 1592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging the dataframe.\n",
    "df= df[['tweet_text', 'clean_tweet_text','emotion_in_tweet_is_directed_at','Tweet_Directed_at',\n",
    "       'is_there_an_emotion_directed_at_a_brand_or_product']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From above display of the value counts, the category_words columns have 1781 null entries.\n",
    "* Loop through the 'category_words' to determine which entries were null. For the indices of the null entries, check if they are present in the 'emotion_in_tweet_is_directed_at' column. If present, fill in the null entries in the category_words.\n",
    "* Access the value counts of the category_words column to verify the decrease in the null entries. Notice a decrease in the number of null entries.\n",
    "* Proceed to drop the rows with null entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    8717\n",
       "True      353\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for rows where emotion_in_tweet_is_directed_at has data, but clean_tweet_text is blank\n",
    "condition_a_data_b_blank = (df['emotion_in_tweet_is_directed_at'].notna() & (df['emotion_in_tweet_is_directed_at'] != \"\") & \n",
    "                            (df['Tweet_Directed_at'].isna() | (df['Tweet_Directed_at'] == \"\")))\n",
    "\n",
    "\n",
    "condition_a_data_b_blank.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet_Directed_at\n",
       "Google                             2196\n",
       "iPad                               1801\n",
       "                                   1428\n",
       "Apple                              1263\n",
       "iPhone                             1058\n",
       "iPad Apple                          568\n",
       "Android                             259\n",
       "iPhone Android                      118\n",
       "iPhone iPad                         103\n",
       "iPad or iPhone App                   74\n",
       "Android Android App                  30\n",
       "iPad Android                         23\n",
       "iPhone Apple                         23\n",
       "Google Apple                         23\n",
       "Android App                          16\n",
       "Google Android                       15\n",
       "Other Google product or service      13\n",
       "Other Apple product or service       13\n",
       "iPad Google                          10\n",
       "iPhone Android Android App           10\n",
       "iPhone iPad Android                   8\n",
       "Android Apple                         7\n",
       "iPhone iPad Apple                     4\n",
       "iPhone Google                         3\n",
       "iPhone iPad Google                    2\n",
       "iPhone Google Android                 2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the 'category_words' column with the values from 'emotion_in_tweet_is_directed_at'\n",
    "df.loc[condition_a_data_b_blank, 'Tweet_Directed_at'] = df.loc[condition_a_data_b_blank, 'emotion_in_tweet_is_directed_at']\n",
    "# Uncomment the cell below to show the value counts\n",
    "df['Tweet_Directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a mapping for the either google products, apple products, unknown and IRR. Map this dictionary to create a column to show which company the tweet was directed at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Product\n",
       "Apple Products     0.541014\n",
       "Google Products    0.278831\n",
       "Unknown            0.157442\n",
       "IRR                0.022712\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 1595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define mapping for fewer categories\n",
    "category_mapping = {\n",
    "    'Google': 'Google Products',\n",
    "    'iPad': 'Apple Products',\n",
    "    '': 'Unknown',\n",
    "    'Apple': 'Apple Products',\n",
    "    'iPhone': 'Apple Products',\n",
    "    'iPad Apple': 'Apple Products',\n",
    "    'Android': 'Google Products',\n",
    "    'iPhone Android': 'IRR',\n",
    "    'iPhone iPad': 'Apple Products',\n",
    "    'iPad or iPhone App': 'Apple Products',\n",
    "    'Android Android App': 'Google Products',\n",
    "    'iPad Android': 'IRR',\n",
    "    'iPhone Apple': 'Apple Products',\n",
    "    'Google Apple': 'IRR',\n",
    "    'Android App': 'Google Products',\n",
    "    'Google Android': 'Google Products',\n",
    "    'Other Google product or service': 'Google Products',\n",
    "    'Other Apple product or service': 'Apple Products',\n",
    "    'iPad Google': 'IRR',\n",
    "    'iPhone Android Android App': 'IRR',\n",
    "    'iPhone iPad Android': 'IRR',\n",
    "    'Android Apple': 'IRR',\n",
    "    'iPhone iPad Apple': 'Apple Products',\n",
    "    'iPhone Google': 'IRR',\n",
    "    'iPhone iPad Google': 'IRR',\n",
    "    'iPhone Google Android': 'IRR'\n",
    "}\n",
    "\n",
    "\n",
    "# Apply mapping to the dataframe\n",
    "df['Company_Product'] = df['Tweet_Directed_at'].map(category_mapping)\n",
    "df.head()\n",
    "# Display the result\n",
    "df['Company_Product'].value_counts(normalize= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any null values in the Company_product column\n",
    "df['Company_Product'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have now created a column where we have been able to map the various products. The missing values/ null values are now denoted with the word \"Unknown\".\n",
    "* Proceed to drop the \"Unknown\" and \"IRR\" which represents irrelevant categories in the column.\n",
    "* Then proceed to drop the 'emotion_in_tweet_is_directed_at' column, because the 'Company_product' is a better representative of this column. Now we have successfully dealt with the missing values. Proceed to dealing with the clean_tweet_text column semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_text                                               0\n",
      "clean_tweet_text                                         0\n",
      "emotion_in_tweet_is_directed_at                       4216\n",
      "Tweet_Directed_at                                        0\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "Company_Product                                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Droping rows with null entries\n",
    "df = df[(df['Company_Product'] != 'Unknown') & (df['Company_Product'] != 'IRR')]\n",
    "df = df.reset_index(drop=True)\n",
    "# Confirm the null entries\n",
    "Pf.check_for_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "      <th>Tweet_Directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Company_Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.</td>\n",
       "      <td>i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw</td>\n",
       "      <td>know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at</td>\n",
       "      <td>iPhone iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.</td>\n",
       "      <td>can not wait for  2 also. they should sale them down at .</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as crashy as this year's iphone app. #sxsw</td>\n",
       "      <td>i hope this year's festival isn't as crashy as this year's iphone app.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa mayer (google), tim o'reilly (tech books/conferences) &amp;amp; matt mullenweg (wordpress)</td>\n",
       "      <td>great stuff on fri : marissa mayer (google), tim o'reilly (tech books/conferences) &amp;amp; matt mullenweg (wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>@mention yup, but i don't have a third app yet. i'm on android, any suggestions? #sxsw cc: @mention</td>\n",
       "      <td>yup, but i don't have a third app yet. i'm on android, any suggestions?  cc:</td>\n",
       "      <td>Android</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>ipad everywhere. #sxsw {link}</td>\n",
       "      <td>ipad everywhere.  {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>google's zeiger, a physician never reported potential ae. yet fda relies on physicians. &amp;quot;we're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>google's zeiger, a physician never reported potential ae. yet fda relies on physicians. &amp;quot;we're operating w/out data.&amp;quot;</td>\n",
       "      <td>Google</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>some verizon iphone customers complained their time fell back an hour this weekend.  of course they were the new yorkers who attended #sxsw.</td>\n",
       "      <td>some verizon iphone customers complained their time fell back an hour this weekend.  of course they were the new yorkers who attended .</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>ï¡ïàü_êîò£áââ_£â_ûârt @mention google tests ûïcheck-in offersû at #sxsw {link}</td>\n",
       "      <td>ï¡ïàü_êîò£áââ_£â_ûârt  google tests ûïcheck-in offersû at  {link}</td>\n",
       "      <td>Google</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7436 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.   \n",
       "1           @jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw   \n",
       "2                                                                       @swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.   \n",
       "3                                                                    @sxsw i hope this year's festival isn't as crashy as this year's iphone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on fri #sxsw: marissa mayer (google), tim o'reilly (tech books/conferences) &amp; matt mullenweg (wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "7431                                                @mention yup, but i don't have a third app yet. i'm on android, any suggestions? #sxsw cc: @mention   \n",
       "7432                                                                                                                      ipad everywhere. #sxsw {link}   \n",
       "7433  google's zeiger, a physician never reported potential ae. yet fda relies on physicians. &quot;we're operating w/out data.&quot; #sxsw #health2dev   \n",
       "7434       some verizon iphone customers complained their time fell back an hour this weekend.  of course they were the new yorkers who attended #sxsw.   \n",
       "7435                                           ï¡ïàü_êîò£áââ_£â_ûârt @mention google tests ûïcheck-in offersû at #sxsw {link}   \n",
       "\n",
       "                                                                                                                             clean_tweet_text  \\\n",
       "0                                         i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .   \n",
       "1                        know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at    \n",
       "2                                                                                   can not wait for  2 also. they should sale them down at .   \n",
       "3                                                                     i hope this year's festival isn't as crashy as this year's iphone app.    \n",
       "4                         great stuff on fri : marissa mayer (google), tim o'reilly (tech books/conferences) &amp; matt mullenweg (wordpress)   \n",
       "...                                                                                                                                       ...   \n",
       "7431                                                            yup, but i don't have a third app yet. i'm on android, any suggestions?  cc:    \n",
       "7432                                                                                                                 ipad everywhere.  {link}   \n",
       "7433        google's zeiger, a physician never reported potential ae. yet fda relies on physicians. &quot;we're operating w/out data.&quot;     \n",
       "7434  some verizon iphone customers complained their time fell back an hour this weekend.  of course they were the new yorkers who attended .   \n",
       "7435                                              ï¡ïàü_êîò£áââ_£â_ûârt  google tests ûïcheck-in offersû at  {link}   \n",
       "\n",
       "     Tweet_Directed_at is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0               iPhone                                   Negative emotion   \n",
       "1          iPhone iPad                                   Positive emotion   \n",
       "2                 iPad                                   Positive emotion   \n",
       "3               iPhone                                   Negative emotion   \n",
       "4               Google                                   Positive emotion   \n",
       "...                ...                                                ...   \n",
       "7431           Android                 No emotion toward brand or product   \n",
       "7432              iPad                                   Positive emotion   \n",
       "7433            Google                 No emotion toward brand or product   \n",
       "7434            iPhone                 No emotion toward brand or product   \n",
       "7435            Google                 No emotion toward brand or product   \n",
       "\n",
       "      Company_Product  \n",
       "0      Apple Products  \n",
       "1      Apple Products  \n",
       "2      Apple Products  \n",
       "3      Apple Products  \n",
       "4     Google Products  \n",
       "...               ...  \n",
       "7431  Google Products  \n",
       "7432   Apple Products  \n",
       "7433  Google Products  \n",
       "7434   Apple Products  \n",
       "7435  Google Products  \n",
       "\n",
       "[7436 rows x 5 columns]"
      ]
     },
     "execution_count": 1598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the emotion_in_tweet_is_directed_at column \n",
    "df.drop('emotion_in_tweet_is_directed_at', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    3887\n",
       "Positive emotion                      2856\n",
       "Negative emotion                       555\n",
       "I can't tell                           138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the tweet_text \"is_there_an_emotion_directed_at_a_brand_or_product\" column\n",
    "# Recall that this column also has unique values , we will look at them\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "      <th>Tweet_Directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Company_Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.</td>\n",
       "      <td>i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw</td>\n",
       "      <td>know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at</td>\n",
       "      <td>iPhone iPad</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.</td>\n",
       "      <td>can not wait for  2 also. they should sale them down at .</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as crashy as this year's iphone app. #sxsw</td>\n",
       "      <td>i hope this year's festival isn't as crashy as this year's iphone app.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa mayer (google), tim o'reilly (tech books/conferences) &amp;amp; matt mullenweg (wordpress)</td>\n",
       "      <td>great stuff on fri : marissa mayer (google), tim o'reilly (tech books/conferences) &amp;amp; matt mullenweg (wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw   \n",
       "2                                                              @swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.   \n",
       "3                                                           @sxsw i hope this year's festival isn't as crashy as this year's iphone app. #sxsw   \n",
       "4          @sxtxstate great stuff on fri #sxsw: marissa mayer (google), tim o'reilly (tech books/conferences) &amp; matt mullenweg (wordpress)   \n",
       "\n",
       "                                                                                                        clean_tweet_text  \\\n",
       "0                    i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .   \n",
       "1   know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at    \n",
       "2                                                              can not wait for  2 also. they should sale them down at .   \n",
       "3                                                i hope this year's festival isn't as crashy as this year's iphone app.    \n",
       "4    great stuff on fri : marissa mayer (google), tim o'reilly (tech books/conferences) &amp; matt mullenweg (wordpress)   \n",
       "\n",
       "  Tweet_Directed_at is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0            iPhone                                           Negative   \n",
       "1       iPhone iPad                                           Positive   \n",
       "2              iPad                                           Positive   \n",
       "3            iPhone                                           Negative   \n",
       "4            Google                                           Positive   \n",
       "\n",
       "   Company_Product  \n",
       "0   Apple Products  \n",
       "1   Apple Products  \n",
       "2   Apple Products  \n",
       "3   Apple Products  \n",
       "4  Google Products  "
      ]
     },
     "execution_count": 1601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now streamline the categories into shorter forms such as \"positive\",\"negative\",\"Neutral\" \n",
    "# and \"Unknown\" using mapping\n",
    "Updated_emotion_categories = {'Negative emotion': 'Negative', 'Positive emotion': 'Positive', \n",
    "                'No emotion toward brand or product': 'Neutral', \n",
    "                \"I can't tell\": 'Unknown'}\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].map(Updated_emotion_categories)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>3887</td>\n",
       "      <td>52.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>2856</td>\n",
       "      <td>38.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>555</td>\n",
       "      <td>7.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>138</td>\n",
       "      <td>1.86%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Count Percentage\n",
       "is_there_an_emotion_directed_at_a_brand_or_product                  \n",
       "Neutral                                              3887     52.27%\n",
       "Positive                                             2856     38.41%\n",
       "Negative                                              555      7.46%\n",
       "Unknown                                               138      1.86%"
      ]
     },
     "execution_count": 1602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the value counts for the emotion-directed column\n",
    "Count_emotion = df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each category\n",
    "percentage_emotion = df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Combine both count and percentage into a DataFrame\n",
    "result_emotion = pd.DataFrame({\n",
    "    'Count': Count_emotion,\n",
    "    'Percentage': percentage_emotion.apply(lambda x: f\"{x:.2f}%\")  # Format percentage to 2 decimal places\n",
    "})\n",
    "\n",
    "result_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "      <th>Tweet_Directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Company_Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ûï@mention &amp;quot;apple has opened a pop-up store in austin so the nerds in town for #sxsw can get their new ipads. {link} #wow</td>\n",
       "      <td>&amp;quot;apple has opened a pop-up store in austin so the nerds in town for  can get their new ipads. {link}</td>\n",
       "      <td>iPad Apple</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>just what america needs. rt @mention google to launch major new social network called circles, possibly today {link} #sxsw</td>\n",
       "      <td>just what america needs. rt  google to launch major new social network called circles, possibly today {link}</td>\n",
       "      <td>Google</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>the queue at the apple store in austin is four blocks long. crazy stuff! #sxsw</td>\n",
       "      <td>the queue at the apple store in austin is four blocks long. crazy stuff!</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>hope it's better than wave rt @mention buzz is: google's previewing a social networking platform at #sxsw: {link}</td>\n",
       "      <td>hope it's better than wave rt  buzz is: google's previewing a social networking platform at : {link}</td>\n",
       "      <td>Google</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>syd #sxsw crew your iphone extra juice pods have been procured.</td>\n",
       "      <td>syd  crew your iphone extra juice pods have been procured.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>it's funny watching a room full of people hold their ipad in the air to take a photo. like a room full of tablets staring you down. #sxsw</td>\n",
       "      <td>it's funny watching a room full of people hold their ipad in the air to take a photo. like a room full of tablets staring you down.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7382</th>\n",
       "      <td>@mention yeah, we have @mention , google has nothing on us :) #sxsw</td>\n",
       "      <td>yeah, we have  , google has nothing on us :)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>@mention yes, the google presentation was not exactly what i was expecting. #sxsw</td>\n",
       "      <td>yes, the google presentation was not exactly what i was expecting.</td>\n",
       "      <td>Google</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Google Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>&amp;quot;do you know what apple is really good at? making you feel bad about your xmas present!&amp;quot; - seth meyers on ipad2 #sxsw #doyoureallyneedthat?</td>\n",
       "      <td>&amp;quot;do you know what apple is really good at? making you feel bad about your xmas present!&amp;quot; - seth meyers on ipad2  ?</td>\n",
       "      <td>iPad Apple</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>how much you want to bet apple is disproportionately stocking the #sxsw pop-up store with ipad 2? the influencer/hipsters thank you</td>\n",
       "      <td>how much you want to bet apple is disproportionately stocking the  pop-up store with ipad 2? the influencer/hipsters thank you</td>\n",
       "      <td>iPad Apple</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 tweet_text  \\\n",
       "76                          ûï@mention &quot;apple has opened a pop-up store in austin so the nerds in town for #sxsw can get their new ipads. {link} #wow   \n",
       "189                              just what america needs. rt @mention google to launch major new social network called circles, possibly today {link} #sxsw   \n",
       "286                                                                          the queue at the apple store in austin is four blocks long. crazy stuff! #sxsw   \n",
       "308                                       hope it's better than wave rt @mention buzz is: google's previewing a social networking platform at #sxsw: {link}   \n",
       "344                                                                                         syd #sxsw crew your iphone extra juice pods have been procured.   \n",
       "...                                                                                                                                                     ...   \n",
       "7374              it's funny watching a room full of people hold their ipad in the air to take a photo. like a room full of tablets staring you down. #sxsw   \n",
       "7382                                                                                    @mention yeah, we have @mention , google has nothing on us :) #sxsw   \n",
       "7387                                                                      @mention yes, the google presentation was not exactly what i was expecting. #sxsw   \n",
       "7405  &quot;do you know what apple is really good at? making you feel bad about your xmas present!&quot; - seth meyers on ipad2 #sxsw #doyoureallyneedthat?   \n",
       "7413                    how much you want to bet apple is disproportionately stocking the #sxsw pop-up store with ipad 2? the influencer/hipsters thank you   \n",
       "\n",
       "                                                                                                                          clean_tweet_text  \\\n",
       "76                              &quot;apple has opened a pop-up store in austin so the nerds in town for  can get their new ipads. {link}    \n",
       "189                          just what america needs. rt  google to launch major new social network called circles, possibly today {link}    \n",
       "286                                                              the queue at the apple store in austin is four blocks long. crazy stuff!    \n",
       "308                                   hope it's better than wave rt  buzz is: google's previewing a social networking platform at : {link}   \n",
       "344                                                                             syd  crew your iphone extra juice pods have been procured.   \n",
       "...                                                                                                                                    ...   \n",
       "7374  it's funny watching a room full of people hold their ipad in the air to take a photo. like a room full of tablets staring you down.    \n",
       "7382                                                                                         yeah, we have  , google has nothing on us :)    \n",
       "7387                                                                   yes, the google presentation was not exactly what i was expecting.    \n",
       "7405          &quot;do you know what apple is really good at? making you feel bad about your xmas present!&quot; - seth meyers on ipad2  ?   \n",
       "7413        how much you want to bet apple is disproportionately stocking the  pop-up store with ipad 2? the influencer/hipsters thank you   \n",
       "\n",
       "     Tweet_Directed_at is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "76          iPad Apple                                            Unknown   \n",
       "189             Google                                            Unknown   \n",
       "286              Apple                                            Unknown   \n",
       "308             Google                                            Unknown   \n",
       "344             iPhone                                            Unknown   \n",
       "...                ...                                                ...   \n",
       "7374              iPad                                            Unknown   \n",
       "7382            Google                                            Unknown   \n",
       "7387            Google                                            Unknown   \n",
       "7405        iPad Apple                                            Unknown   \n",
       "7413        iPad Apple                                            Unknown   \n",
       "\n",
       "      Company_Product  \n",
       "76     Apple Products  \n",
       "189   Google Products  \n",
       "286    Apple Products  \n",
       "308   Google Products  \n",
       "344    Apple Products  \n",
       "...               ...  \n",
       "7374   Apple Products  \n",
       "7382  Google Products  \n",
       "7387  Google Products  \n",
       "7405   Apple Products  \n",
       "7413   Apple Products  \n",
       "\n",
       "[138 rows x 5 columns]"
      ]
     },
     "execution_count": 1603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of \"Unknown\" emotion category\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "Emotion_Unknown = df[df['is_there_an_emotion_directed_at_a_brand_or_product']=='Unknown']\n",
    "Emotion_Unknown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the first 5 rows, it is clear that, it is not clear what emotion is really being captured in the tweet, Some of the tweets might be sarcastic or actually genuine but we cannot tell. However from the value count seen above , the number of the \"Unknown\" emotion is not significant(1.8% of the total data in the \"emotion\" column). It is therefore more prudent to drop them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "Neutral     3887\n",
       "Positive    2856\n",
       "Negative     555\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=df[df['is_there_an_emotion_directed_at_a_brand_or_product']!='Unknown']\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.2 Additiona Data Cleaning & EDA with NLTK\n",
    "\n",
    "For this section we will start by focusing on Positive and the Negative emotions captured in the \"is_there_an_emotion_directed_at_a_brand-or_product column as it is our objective to analyze those two categories.\n",
    "\n",
    "We will use first start by removing the following from the clean_tweet_text column :\n",
    "\n",
    "1. Remove URLs\n",
    "2. remove non-alphanumeric characters\n",
    "3. Remove numbers/ digits\n",
    "\n",
    "#####  3.2.1\n",
    "* In this section we access the clean_tweet_text column check for the appropriate checks in the text. For instance, removal of special characters, Urls and numbers/digits.\n",
    "* Create a function that removes all the instances above.\n",
    "* Access specific text, perform the transformations and apply to the whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great  ipad app from  http://tinyurl.com/4nqv92l'"
      ]
     },
     "execution_count": 1605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = df[\"clean_tweet_text\"][13]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def cleaning_tokens(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    token = re.sub(r'^\\d+[a-zA-Z]+$', '', text) # Number followed by letters (e.g., 141st)\n",
    "    token = re.sub(r'^[a-zA-Z]+\\d+\\d+$', '', text) # Letters followed by number followed by numbers (e.g., abc12345)\n",
    "    token = re.sub(r'^\\d+(\\.\\d+)?$', '', text) # Any number (integer or decimal)\n",
    "    token = re.sub(r'https?:\\/\\/\\S+|www\\.\\S+', '', text) # Match URLs starting with http(s):// or www.\n",
    "    token = re.sub(r'^[a-zA-Z]+\\d+[a-zA-Z]+$', '', text)  # Letters followed by number followed by letters (e.g., abc123def)\n",
    "    return token\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def cleaning_tokens(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    token = re.sub(r'^\\d+[a-zA-Z]+$', '', text) # Number followed by letters (e.g., 141st)\n",
    "    token = re.sub(r'^[a-zA-Z]+\\d+\\d+$', '', text) # Letters followed by number followed by numbers (e.g., abc12345)\n",
    "    token = re.sub(r'^\\d+(\\.\\d+)?$', '', text) # Any number (integer or decimal)\n",
    "    token = re.sub(r'^(http[s]?://\\S+)$', '', text, flags=re.MULTILINE) # Match URLs starting with http(s):// or www.\n",
    "    token = re.sub(r'^[a-zA-Z]+\\d+[a-zA-Z]+$', '', text)  # Letters followed by number followed by letters (e.g., abc123def)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaned_sentence = cleaning_tokens(sentence)\n",
    "cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google to launch major new social network called circles, possibly today {link}  rt  via '"
      ]
     },
     "execution_count": 1606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = df[\"clean_tweet_text\"][644]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google',\n",
       " 'to',\n",
       " 'launch',\n",
       " 'major',\n",
       " 'new',\n",
       " 'social',\n",
       " 'network',\n",
       " 'called',\n",
       " 'circles',\n",
       " 'possibly',\n",
       " 'today',\n",
       " 'link',\n",
       " 'rt',\n",
       " 'via']"
      ]
     },
     "execution_count": 1607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the regexptokenizer\n",
    "# Check how it works on the example sentence above\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice that the regexpTokenizer removes all the special characters, including urls. It splits the specific words and puts them into a list. However the it does not remove the stopwords/ filler words and numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1608,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1608-b360cf459f51>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_tokenized\"] = df[\"clean_tweet_text\"].apply(tokenizer.tokenize)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_tweet_text</th>\n",
       "      <th>Tweet_Directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Company_Product</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.</td>\n",
       "      <td>i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Apple Products</td>\n",
       "      <td>[have, 3g, iphone, after, hrs, tweeting, at, it, was, dead, need, to, upgrade, plugin, stations, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw</td>\n",
       "      <td>know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at</td>\n",
       "      <td>iPhone iPad</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple Products</td>\n",
       "      <td>[know, about, awesome, ipad, iphone, app, that, you, ll, likely, appreciate, for, its, design, also, they, re, giving, free, ts, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.</td>\n",
       "      <td>can not wait for  2 also. they should sale them down at .</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple Products</td>\n",
       "      <td>[can, not, wait, for, also, they, should, sale, them, down, at]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw   \n",
       "2                                                              @swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.   \n",
       "\n",
       "                                                                                                        clean_tweet_text  \\\n",
       "0                    i have a 3g iphone. after 3 hrs tweeting at , it was dead!  i need to upgrade. plugin stations at .   \n",
       "1   know about  ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at    \n",
       "2                                                              can not wait for  2 also. they should sale them down at .   \n",
       "\n",
       "  Tweet_Directed_at is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0            iPhone                                           Negative   \n",
       "1       iPhone iPad                                           Positive   \n",
       "2              iPad                                           Positive   \n",
       "\n",
       "  Company_Product  \\\n",
       "0  Apple Products   \n",
       "1  Apple Products   \n",
       "2  Apple Products   \n",
       "\n",
       "                                                                                                                         text_tokenized  \n",
       "0                                  [have, 3g, iphone, after, hrs, tweeting, at, it, was, dead, need, to, upgrade, plugin, stations, at]  \n",
       "1  [know, about, awesome, ipad, iphone, app, that, you, ll, likely, appreciate, for, its, design, also, they, re, giving, free, ts, at]  \n",
       "2                                                                       [can, not, wait, for, also, they, should, sale, them, down, at]  "
      ]
     },
     "execution_count": 1608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column with tokenized data\n",
    "df[\"text_tokenized\"] = df[\"clean_tweet_text\"].apply(tokenizer.tokenize)\n",
    "# Display full text\n",
    "#df.style.set_properties(**{'text-align': 'left'})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great', 'ipad', 'app', 'from', 'http', 'tinyurl', 'com', '4nqv92l']"
      ]
     },
     "execution_count": 1611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Sentence to test how the function is working\n",
    "sentence = df[\"text_tokenized\"][13]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1612,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_tokens(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    token = re.sub(r'^\\d+[a-zA-Z]+$', '', text) # Number followed by letters (e.g., 141st)\n",
    "    token = re.sub(r'^[a-zA-Z]+\\d+\\d+$', '', text) # Letters followed by number followed by numbers (e.g., abc12345)\n",
    "    token = re.sub(r'^\\d+(\\.\\d+)?$', '', text) # Any number (integer or decimal)\n",
    "    token = re.sub(r'http[s]?:\\/\\/\\S+|www\\.\\S+', '', text) # Match URLs starting with http(s):// or www.\n",
    "    token = re.sub(r'^[a-zA-Z]+\\d+[a-zA-Z]+$', '', text)  # Letters followed by number followed by letters (e.g., abc123def)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentence = cleaning_tokens(sentence)\n",
    "cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text_tokenized'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3653\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3654\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text_tokenized'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1576-1d5d3a9fdbd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create Sentence to test how the function is working\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text_tokenized\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m644\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3761\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3762\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3654\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3655\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3656\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3657\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text_tokenized'"
     ]
    }
   ],
   "source": [
    "# Create Sentence to test how the function is working\n",
    "sentence = df[\"text_tokenized\"][644]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text (remove unwanted characters and convert to lowercase)\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # confirm mentions (@user)\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    return text\n",
    "\n",
    "#df['cleaned_tweet'] = df['tweet_text'].apply(clean_text)\n",
    "cleaned_sentence = clean_text(sentence)\n",
    "cleaned_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"text_tokenized\"]= df[\"text_tokenized\"].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying 15 most common tokens\n",
    "from nltk import FreqDist\n",
    "tokens_count = [token for tokens in df[\"text_tokenized\"] for token in tokens]\n",
    "freq = FreqDist(tokens_count)\n",
    "freq.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed with further cleaning of the text, it is clear from the above results that stopwords dominated the texts and therefore need to be removed. It is also noted there are words such as \"Link\" that need to be investigated to determine whether it refers to a link to a website or something else. We will also check on the letters \"rt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"text_tokenized\"][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the list of English stop words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words += list()\n",
    "# Function to remove stop words\n",
    "def remove_stop_words(tokens_list):\n",
    "    \"\"\"\n",
    "    Removes stop words from a list of tokens.\n",
    "    Arguments:\n",
    "    - tokens_list: List of tokenized words.\n",
    "    \n",
    "    Returns:\n",
    "    - List of tokens without stop words.\n",
    "    \"\"\"\n",
    "    return [word for word in tokens_list if word.lower() not in stop_words]\n",
    "\n",
    "# Apply the function to the tokenized text column\n",
    "df[\"text_tokenized\"] = df[\"text_tokenized\"].apply(remove_stop_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying 10 most common tokens\n",
    "from nltk import FreqDist\n",
    "tokens_count = [token for tokens in df[\"text_tokenized\"] for token in tokens]\n",
    "freq = FreqDist(tokens_count)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for rows where 'link' is in the tokenized text\n",
    "matching_rows = df[df['text_tokenized'].apply(lambda tokens: 'link' in tokens)]\n",
    "\n",
    "# Display the first 5 tweet texts where 'link' is found\n",
    "print(matching_rows['tweet_text'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for rows where 'link' is in the tokenized text\n",
    "matching_rows = df[df['text_tokenized'].apply(lambda tokens: 'rt' in tokens)]\n",
    "\n",
    "# Display the first 5 tweet texts where 'link' is found\n",
    "print(matching_rows['tweet_text'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that the word link refers to URLS or HTTPs and the rt refers to retweet. This is not necessary for our analysis. Therefore, we will add to our stopwords list and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words += ['link', 'rt']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_tokenized\"] = df[\"text_tokenized\"].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for rows where 'link' is in the tokenized text\n",
    "matching_rows = df[df['text_tokenized'].apply(lambda tokens: 'link' in tokens)]\n",
    "\n",
    "# Display the first 5 tweet texts where 'link' is found\n",
    "print(matching_rows['tweet_text'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for rows where 'link' is in the tokenized text\n",
    "matching_rows = df[df['text_tokenized'].apply(lambda tokens: 'rt' in tokens)]\n",
    "\n",
    "# Display the first 5 tweet texts where 'link' is found\n",
    "print(matching_rows['tweet_text'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying 15 most common tokens\n",
    "from nltk import FreqDist\n",
    "tokens_count = [token for tokens in df[\"text_tokenized\"] for token in tokens]\n",
    "freq = FreqDist(tokens_count)\n",
    "freq.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing 'link' and 'rt', one can see a more refined group of words above.\n",
    "From the results above we can already see ipad and google being the most popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further to removing 'link' and 'rt' , we will proceed to remove one letter and two letter words , except the word 'no' which we have determined can be used to convey emotion.\n",
    "This way we will minimize having unnessary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove two-letter unnecessary words like 'at', 'i' and others, keeping exceptions like 'no'\n",
    "def remove_two_letter_words(tokens):\n",
    "    return [word for word in tokens if len(word) != 2 or word.lower() == 'no']\n",
    "\n",
    "# Apply the function to the 'text_tokenized' column\n",
    "df['text_tokenized'] = df['text_tokenized'].apply(remove_two_letter_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed to lematization : Lematization is prefered to stemming because it is reduces a word to its base or root form (lemma) based on its linguistic meaning and context and not like stemming which reduces a word to its root form by stripping affixes, without considering linguistic context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply lemmatization to the 'text_tokenized' column\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize tokens\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Apply lemmatization to the 'text_tokenized' column\n",
    "df['text_tokenized_lemmatized'] = df['text_tokenized'].apply(lemmatize_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('cleaned_dataframe.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORATORY DATA ANALYSIS \n",
    "##### 1. Looking at the most popular words\n",
    "##### 2. Looking at popular words tied to positive emotion\n",
    "##### 3. Looking at popular words tired to negative emotion\n",
    "##### 4. Distribution of positive , negative and neutral emotion for both Apple and Google\n",
    "##### 5. Looking at distribution of words tired to Apple and Google\n",
    "##### 6. Looking at how Apple and Google is tired to a positive emotion \n",
    "##### 7. Looking at how Apple and Google is tired to a negative emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the top 10 most popular words, @user_accounts and hashtags\n",
    "# 25 Most popular words\n",
    "\n",
    "from nltk import FreqDist\n",
    "tokens_count = [token for tokens in df[\"text_tokenized\"] for token in tokens]\n",
    "freq = FreqDist(tokens_count)\n",
    "freq.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numerical values using regex\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+','', text)\n",
    "# Check if the function works with our sentence\n",
    "clean_sentence = remove_numbers(sentence)\n",
    "clean_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
